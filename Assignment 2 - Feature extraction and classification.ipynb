{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609bcc26",
   "metadata": {},
   "source": [
    "# Assignment 2 - Feature extraction and classification\n",
    "\n",
    "Note: This notebook file for the assignment has deviations from the course guide with respect to the structure, sentence framing, question framing and numbering. Please consider this notebook file structure as the final structure and follow this.\n",
    "\n",
    "In this assignment, you are expected to\n",
    "\n",
    "(1) extract global features from CIFAR10 dataset with one of the pre-trained neural networks available in pytorch,\n",
    "\n",
    "(2) classify the dataset using the traditional k-Nearest Neighbours classifier,\n",
    "\n",
    "and\n",
    "\n",
    "(3) implement k-fold cross-validation to evaluate your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b394f7",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4d6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the needed packages for this assignment here\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838957a",
   "metadata": {},
   "source": [
    "When working with Pytorch, dataloader() is a must to know function. Read more about this function and the parameters it accepts in https://blog.paperspace.com/dataloaders-abstractions-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb7db27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2320b0",
   "metadata": {},
   "source": [
    "The variable 'transform' encapsulates the needed transformations of our data. Read more about transforms in https://blog.paperspace.com/dataloaders-abstractions-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3daee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # resize\n",
    "    transforms.Resize(32),\n",
    "    # center-crop\n",
    "    transforms.CenterCrop(32),\n",
    "    # to-tensor\n",
    "    transforms.ToTensor(),\n",
    "    # normalize\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f0e38",
   "metadata": {},
   "source": [
    "### INPUT DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ea732",
   "metadata": {},
   "source": [
    "Load the CIFAR10 dataset from Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53bb75cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
=======
    "# Example solution for the CIFAR dataset - Please, select the one you worked with in Assignment 1\n",
    "dataset = 'CIFAR10'\n",
    "classes = ('plane', 'car', 'bird', \n",
    "           'cat','deer', 'dog', 'frog', \n",
    "           'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data_cifar', train=False, download=True, transform=transform)\n",
>>>>>>> Stashed changes
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb189026",
   "metadata": {},
   "source": [
    "#### Exercise 2.1 - Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57aaaa8",
   "metadata": {},
   "source": [
    "**a)** Write a function **'train_test_split(dataset, ratio)'** which takes a dataset array as an input and returns two dataset arrays- one for training and another for testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b5f5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.2471, -0.2627, -0.2549,  ..., -0.2627, -0.2863, -0.2863],\n",
      "         [-0.1922, -0.2157, -0.4196,  ..., -0.2706, -0.3020, -0.2941],\n",
      "         [-0.1373, -0.1608, -0.4510,  ..., -0.2549, -0.2784, -0.2549],\n",
      "         ...,\n",
      "         [ 0.1216,  0.1686,  0.2000,  ...,  0.1216,  0.1373,  0.1765],\n",
      "         [ 0.2314,  0.2627,  0.2941,  ...,  0.0196,  0.1216,  0.1373],\n",
      "         [ 0.3804,  0.2784,  0.3098,  ..., -0.3333, -0.3020, -0.3333]],\n",
      "\n",
      "        [[-0.2471, -0.2784, -0.2863,  ..., -0.3020, -0.3333, -0.3412],\n",
      "         [-0.2078, -0.2471, -0.4824,  ..., -0.3020, -0.3412, -0.3412],\n",
      "         [-0.1686, -0.2000, -0.5294,  ..., -0.2941, -0.3176, -0.2941],\n",
      "         ...,\n",
      "         [-0.0980, -0.0588, -0.0275,  ..., -0.1216, -0.1294, -0.1059],\n",
      "         [-0.0039,  0.0196,  0.0588,  ..., -0.1294, -0.0431, -0.0588],\n",
      "         [ 0.1373,  0.0353,  0.0745,  ..., -0.3725, -0.3569, -0.4039]],\n",
      "\n",
      "        [[-0.7882, -0.7647, -0.6784,  ..., -0.8118, -0.8196, -0.8118],\n",
      "         [-0.6941, -0.6000, -0.6471,  ..., -0.8196, -0.8431, -0.8275],\n",
      "         [-0.5686, -0.4745, -0.6314,  ..., -0.8275, -0.8353, -0.8039],\n",
      "         ...,\n",
      "         [-0.4980, -0.4275, -0.3725,  ..., -0.5765, -0.5765, -0.5529],\n",
      "         [-0.3020, -0.2627, -0.2157,  ..., -0.4745, -0.3804, -0.3961],\n",
      "         [-0.0510, -0.1529, -0.1294,  ..., -0.4667, -0.4431, -0.4902]]]), 2)\n",
      "2\n"
     ]
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "def train_test_split(dataset, ratio):\n",
    "    \n",
    "    # Ex. 2.1a your code here\n",
    "    \n",
    "    return training_data,testing_data"
=======
    "def train_test_split(dataset, ratio, random_state=None):\n",
    "    # CIFAR10 already has a test dataset (train=False) available\n",
    "    # however, we split the train dataset into a new train and test set\n",
    "    # ratio is interpreted as the fraction of training samples relative to the total amount of samples\n",
    "    size = len(dataset)\n",
    "    ratio = int(round(ratio*size,0))\n",
    "    if random_state is not None:\n",
    "        training_data, testing_data = torch.utils.data.random_split(dataset, [ratio, size-ratio], generator=torch.Generator().manual_seed(random_state))\n",
    "    else:\n",
    "        training_data, testing_data = torch.utils.data.random_split(dataset, [ratio, size-ratio])\n",
    "    return training_data,testing_data\n",
    "\n",
    "randomseed, ratio = 17, 0.75\n",
    "dataset_train, dataset_test = train_test_split(dataset, ratio, random_state=randomseed)\n",
    "y_train, y_test = train_test_split(dataset.targets, ratio, random_state=randomseed)\n",
    "\n",
    "print(dataset_train[1])\n",
    "print(y_train[1])"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910f160f",
   "metadata": {},
   "source": [
    "### FEATURE EXTRACTION\n",
    "\n",
    "Extract descriptors from the images in your train and test dataset. The dataset split should remain the same for all the experiments if you want to be fair when comparing performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032fccdb",
   "metadata": {},
   "source": [
<<<<<<< Updated upstream
    "#### Exercise 2.2 - Feature 1 - RGB descriptor\n",
    "\n",
    "Implement the same code you wrote for extracting the overall RGB descriptors(of size n x 24) as in assignment 1 here."
=======
    "## Exercise: Feature 1 - RGB descriptors\n",
    "\n",
    "Following the code you implement in Assignment 1, extract R, G, and B descriptors from the images and concatenate them to create a 1D feature vector of 24 values."
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f654967",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "# Ex.2.2 your code here"
=======
    "# your code here\n",
    "from itertools import product\n",
    "\n",
    "def RGBextractor(dataset, bins=8):\n",
    "    # from Assignment 1\n",
    "    RGBfeatures = []\n",
    "\n",
    "    for d in dataset:\n",
    "        extract = []\n",
    "        #with d[0] as img:\n",
    "        img = d[0]\n",
    "        for i in range(3):\n",
    "            # create normalized histogram per channel\n",
    "            hist, binedge = np.histogram(img[i],bins=bins,range=[-1,1],density=True)\n",
    "            extract.extend(list(hist))\n",
    "        RGBfeatures.append(extract)\n",
    "\n",
    "    # convert to dataframe\n",
    "    colnames = list(product(['R', 'G', 'B'], range(bins)))\n",
    "    colnames = [i[0]+str(i[1]) for i in colnames]\n",
    "    RGBfeatures = pd.DataFrame(RGBfeatures, columns = colnames)\n",
    "\n",
    "    # add label\n",
    "    #RGBfeatures['label'] = dataset.targets\n",
    "    return RGBfeatures\n",
    "\n",
    "RGBfeatures = RGBextractor(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "494391d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set\n",
    "RGBfeatures_train, RGBfeatures_test = train_test_split(np.array(RGBfeatures), ratio, randomseed)"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51372d11",
   "metadata": {},
   "source": [
<<<<<<< Updated upstream
    "#### Exercise 2.3 - Feature 2 - Extract CNN descriptors using pre-traind networks\n",
    "\n",
    "Load one of the pretrained network (resnet, alexnet, vgg, squeezenet, densenet, inception) from pytorch to extract global features from the images present in the dataset. \n",
    "We will use the output values from the layer present just before the fully connected layer of the deep network as a descriptor, i.e. we will remove the last fully-connected layer. Therefore, after feed-forwarding the input image through the network, we save the output as the descriptor of the image. We do this for all the images present in the dataset to get the overall CNN descriptors.\n",
=======
    "## Exercise: Feature 2 - Extract descriptors using pre-trained networks\n",
    "\n",
    "Load a pretrained network to extract global features from the images. \n",
    "We will use the values of the last fully connected layer of the deep network as a descriptor, i.e. we will remove the last fully-connected layer. Therefore, after feed-fowarding the input through the network, we save the output as the descriptor of the image.\n",
>>>>>>> Stashed changes
    "\n",
    "You may refer to this link for debugging purposes - https://stackoverflow.com/questions/52548174/how-to-remove-the-last-fc-layer-from-a-resnet-model-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e04373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
<<<<<<< Updated upstream
    "\n",
    "# Ex.2.3 your code here\n",
=======
    "torch.no_grad() # no backpropagation is needed\n",
>>>>>>> Stashed changes
    "# name of the model you wish to use - it should be selected from this list\n",
    "# [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "resnet18.eval(); # set to evaluation mode\n",
    "# strip last layer\n",
    "#resnet18 = torch.nn.Sequential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c2b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate descriptor data\n",
    "data = None\n",
    "for i in range(len(dataloader)):\n",
    "    # load data in batches, calculate output and store in new tensor\n",
    "    features, labels = next(iter(dataloader))\n",
    "    batch = resnet18(features)\n",
    "    if data is None:\n",
    "        data = batch\n",
    "    else:\n",
    "        data = torch.cat((data, batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1423afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test set\n",
    "data = data.detach().numpy()\n",
    "ResNetfeatures_train, ResNetfeatures_test = train_test_split(data, ratio, randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ddda2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "print(len(ResNetfeatures_train))\n",
    "print(len(ResNetfeatures_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7599bb2b",
   "metadata": {},
   "source": [
    "### PERFORMANCE EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a59fdf",
   "metadata": {},
   "source": [
    "#### Exercise 2.4 - Error function\n",
    "\n",
    "Implement a function to evaluate the accuracy of your prediction. We will rely on the evaluation metric 'accuracy'.\n",
    "\n",
    "You are suggested to also use f-score, recall and precision. Have a look at https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3677bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as met\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    \n",
<<<<<<< Updated upstream
    "    # Ex.2.4 your code here\n",
=======
    "    pr, re, fb, sup = met(actual, predicted)\n",
>>>>>>> Stashed changes
    "    \n",
    "    return fb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b447784",
   "metadata": {},
   "source": [
    "### TRAIN AND TEST YOUR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab251607",
   "metadata": {},
   "source": [
    "#### Exercise 2.5 - k Nearest Neighbour model\n",
    "\n",
    "For this exercise, first split the extracted overall RGB and CNN descriptor to train and test sets with the help of the 'train_test_split()' function that you implemented before.\n",
    "\n",
    "**a)** Apply the classifier with different values of k (number of nearest neighbours) to the train **RGB descriptor** set and evaluate the performance of your models using the accuracy_metric() function that you implemented before.\n",
    "\n",
    "You can have a look at the documentation to understand the parameters that define the learning of the model,\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1470832c",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Use your k-NN - play with the value of the parameters to see how the model performs\n",
    "kvalue_list = [2,4,6,10,15] \n",
    "\n",
    "# Ex.2.5a your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f26dee-1c7b-4498-a6aa-320a2106a5b9",
   "metadata": {},
   "source": [
    "**b)** Apply the classifier with different values of k (number of nearest neighbours) to the train **CNN descriptor** and evaluate the performance of your models using the accuracy_metric() function that you implemented before."
=======
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "import numpy as np"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b90aba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\danie\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected array-like (array or non-string sequence), got <torch.utils.data.dataset.Subset object at 0x0000018DF5F15B20>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5940\\3545647870.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mResNetpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNetKNN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResNetfeatures_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRGBpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ResNet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResNetpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5940\\895201627.py\u001b[0m in \u001b[0;36maccuracy_metric\u001b[1;34m(actual, predicted)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maccuracy_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1544\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average has to be one of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machine_learning\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    271\u001b[0m             \u001b[1;34m\"Expected array-like (array or non-string sequence), got %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected array-like (array or non-string sequence), got <torch.utils.data.dataset.Subset object at 0x0000018DF5F15B20>"
     ]
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "# Ex.2.5b your code here"
=======
    "# Use your k-NN - play with the value of the parameters to see how the model performs\n",
    "\n",
    "kvalue_list = [2]#[2,4,6,10,15]\n",
    "\n",
    "ResNetKNN = [KNeighborsClassifier(n_neighbors=i) for i in kvalue_list]\n",
    "RGBKNN = [KNeighborsClassifier(n_neighbors=i) for i in kvalue_list]\n",
    "\n",
    "for i, k in enumerate(kvalue_list):\n",
    "    RGBKNN[i].fit(RGBfeatures_train, y_train)\n",
    "    ResNetKNN[i].fit(ResNetfeatures_train, y_train)\n",
    "    \n",
    "    RGBpred = RGBKNN[i].predict(RGBfeatures_test)\n",
    "    ResNetpred = ResNetKNN[i].predict(ResNetfeatures_train)\n",
    "    \n",
    "    print('RGB', accuracy_metric(y_test, RGBpred))\n",
    "    print('ResNet', accuracy_metric(y_test, ResNetpred))"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e94c23",
   "metadata": {},
   "source": [
    "#### Exercise 2.6 - Visualize results \n",
    "\n",
    "**a)** Since you already applied PCA to the extracted overall RGB descriptor in assignment 1, now apply PCA to the extracted overall **CNN descriptor**.\n",
    "\n",
    "Steps to follow:\n",
    "\n",
    "1) Choose the kNN classifier with k value that gave you the best results in the previous exercise and use it to make predictions on your train CNN descriptor set.\n",
    "\n",
    "2) Apply PCA on the train set and select the first 2 principal components to represent each sample.\n",
    "\n",
    "2) Plot the principal components representing the samples with empty circles. Use one color per ground truth class lables. On top of this, plot the samples again but now with filled circles. For these filled circles, use the color of the class predicted per sample in step 1. You can note that misclassifications will make the colours not coincide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.2.6a your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a156163-1ee6-42f9-a187-d0738caebf81",
   "metadata": {},
   "source": [
    "**b)** Repeat the steps mentioned before but now on the test CNN descriptor set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86aaad-02cb-4919-826f-0bb254a29da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex.2.6b your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77cbfb5",
   "metadata": {},
   "source": [
    "#### Exercise 2.7 - kNN with k-Fold cross-validation\n",
    "\n",
    "Assess the performance of your implemented kNN using k-Fold cross-validation. \n",
    "\n",
    "Run your implemented function evaluating for k (fold) = 2, 5 and 10. You can rely on the kNN that performed best in the previous exercises.\n",
    "Report the average accuracy and the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f603d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Ex.2.7 your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba435dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SUGGESTION ON HOW TO PRESENT PERFORMANCE OF YOUR KFOLD CROSS VALIDATION ANALYSIS\n",
    "\n",
    "print('Summary results:')\n",
    "print(' ')\n",
    "print(' ')\n",
    "for i,k in enumerate(k_list):\n",
    "    print(k,'-fold cross validation:')  \n",
    "    print('Accuracies per fold: ', avg_acc_list[i]) \n",
    "    \n",
    "    avg_acc = round(sum(avg_acc_list[i])/k,2)\n",
    "    std_list= round(np.std(avg_acc_list[i]),2)\n",
    "    print('Average accuracy: ', avg_acc,'+-', std_list) \n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf70eb",
   "metadata": {},
   "source": [
    "### [Optional] Exercise: further explore by: \n",
    "- implement other classifiers such as SVM or Random Forest, \n",
    "- extract other descriptors from the images such as objects or other local features,\n",
    "- implement the evaluation metrics: recall, precision and f-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a83da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
